{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# python3 run_bwa_mem.py ./../ref/hg38.fa ./../../cunde/FASTQ/ERR1977350_1.fastq ./../../cunde/FASTQ/ERR1977350_2.fastq > test\n",
    "\n",
    "import os, sys, re, argparse\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create specific function for each pipeline steps:\n",
    "STEP 1: Burrow Wheeler Alignement (BWA mem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def run_bwa():\n",
    "def call_bwa(refgen, fastq_r1, fastq_r2, threads = 1, mark_split = \"-M\", bwa_output = \"bwa_output\", my_path = './'):\n",
    "    #execution = 0\n",
    "    try:            \n",
    "        # create bwa output folder\n",
    "        if not os.path.exists(bwa_output):\n",
    "            os.makedirs(bwa_output)\n",
    "        out_file_name = fastq_r1.split(\"_\")[0]\n",
    "        file_out = \"{}/{}/{}.sam\".format(my_path,bwa_output,out_file_name)\n",
    "        #print(file_out)\n",
    "        log_out =  \"{}/{}.log\".format(my_path,bwa_output)\n",
    "\n",
    "        #run bwa mem\n",
    "        cmd = \"bwa mem {} -t {} {} {} {} > {}\".format(mark_split, threads, refgen,fastq_r1,fastq_r2,file_out)\n",
    "        #print(cmd)\n",
    "        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        #get output and errors\n",
    "        outs,errs = proc.communicate()\n",
    "        #out_file = open(os.path.join(my_path,bwa_output), \"w\")\n",
    "        out_log =  open(log_out, \"w\")\n",
    "\n",
    "        # write output (from byte to ascii) in .sam\n",
    "        outs_errs = errs.decode(\"ascii\")\n",
    "        out_log.write(outs_errs)\n",
    "        out_log.close()\n",
    "        execution = file_out\n",
    "\n",
    "        # check exception content\n",
    "    except Exception as e:\n",
    "        #print(str(e))\n",
    "        execution = None\n",
    "    return execution  # return the proc object inclunding binary output and error log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "STEP 2: Samtools .sam files sorting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def run_samtools():\n",
    "def call_samtools_sort(input_sam, threads = 1, output_format = \"BAM\", samtools_output = \"samtools_output\", my_path = './'):\n",
    "    #execution = 0\n",
    "    try:\n",
    "        # create samtools output folder\n",
    "        if not os.path.exists(samtools_output):\n",
    "            os.makedirs(samtools_output)       \n",
    "        file_out = \"{}/{}/{}.sorted.bam\".format(my_path,samtools_output,sample_name)\n",
    "        #print(file_out)\n",
    "        log_out =  \"{}/{}.log\".format(my_path,samtools_output)\n",
    "\n",
    "        # run samtools_sort\n",
    "        cmd = \"samtools sort -@ {} {} -O {} -o {}\".format(threads, input_sam, output_format, file_out)\n",
    "        proc = subprocess.Popen(cmd, shell = True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        #print(cmd)\n",
    "        outs,errs = proc.communicate()\n",
    "        out_errs = errs.decode(\"ascii\")\n",
    "        out_log =  open(log_out, \"w\")\n",
    "        #print(type(outs))\n",
    "        out_log.write(out_errs)\n",
    "        out_log.close()\n",
    "        execution = file_out\n",
    "            \n",
    "    except Exception as e2:\n",
    "        #print(str(e2))\n",
    "        execution = None\n",
    "    return execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "STEP 3: Picard tools to create a sequence dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_picard_CSD\n",
    "def run_picard_CSD(input_ref, ref_genome = \"ref_genome\", my_path = \"./\"):\n",
    "    execution = 0\n",
    "    try:\n",
    "        # create reference genome folder\n",
    "        if not os.path.exists(ref_genome):\n",
    "            os.makedirs(ref_genome)\n",
    "                                \n",
    "        #run Picard CSD and samtools faidx on reference fasta file\n",
    "        out_file_name  = os.path.basename(input_ref).split(\".\") # list of split input bam file name\n",
    "        out_file = \"{}/{}/{}.dict\".format(my_path,ref_genome,out_file_name[0])\n",
    "        cmd = \"java -jar /usr/local/anaconda/share/picard-2.14-0/picard.jar CreateSequenceDictionary R={} O={}\".format(input_ref, out_file)\n",
    "        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        #get output and errors\n",
    "        outs,errs = proc.communicate()\n",
    "        out_log =  open(\"{}.log\".format(out_file_name[0]), \"w\")\n",
    "\n",
    "        #write output\n",
    "        out_errs = errs.decode(\"ascii\")\n",
    "        out_log.write(out_errs)\n",
    "        out_log.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        execution = 1\n",
    "    return execution  #return the proc object inclunding binary output and error log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "STEP 4: Samtools to create an Index of .bam files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_samtools_faidx(input_ref,ref_genome = \"ref_genome\", my_path = \"./\"):\n",
    "    execution = 0\n",
    "    try:\n",
    "        # create reference genome folder\n",
    "        if not os.path.exists(ref_genome):\n",
    "            os.makedirs(ref_genome)\n",
    "                                \n",
    "        #run samtools faidx on reference fasta file\n",
    "        out_file_name  = os.path.basename(input_ref).split(\".\") # list of split input bam file name\n",
    "        out_file = \"{}/{}/{}.dict\".format(my_path,ref_genome,out_file_name[0])\n",
    "        cmd = \"nohup samtools faidx {}\".format(input_ref)\n",
    "        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        #get output and errors\n",
    "        outs,errs = proc.communicate()\n",
    "        out_log =  open(\"{}.log\".format(out_file_name[0]), \"w\")\n",
    "\n",
    "        #write output\n",
    "        out_errs = errs.decode(\"ascii\")\n",
    "        out_log.write(out_errs)\n",
    "        out_log.close()\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "STEP 5: Picard to mark PCR duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def call_picard_md()\n",
    "def call_picard_md(input_bam, picard_MD_output = \"picard_MD_output\", my_path = \"./\"):\n",
    "    execution = 0\n",
    "    try:\n",
    "\n",
    "        # create picard output folder\n",
    "        if not os.path.exists(picard_MD_output):\n",
    "            os.makedirs(picard_MD_output)\n",
    "           \n",
    "        file_out = \"{}/{}/{}.mrkdup.sorted.bam\".format(my_path,picard_MD_output,sample_name)\n",
    "        #print(file_out)\n",
    "        log_out =  \"{}/picard.mrkdup.sorted.bam.log\".format(my_path)\n",
    "        #print(log_out)\n",
    "\n",
    "        # run samtools_sort\n",
    "        picard_path = 'java -Djava.io.tmpdir=./ -jar /usr/local/anaconda/share/picard-2.14-0/picard.jar'\n",
    "        cmd = \"{} MarkDuplicates I={} O={} M={}.metrics.txt\".format(picard_path, input_bam, file_out, file_out)\n",
    "        proc = subprocess.Popen(cmd, shell = True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        #print(cmd)\n",
    "        \n",
    "        # get errors\n",
    "        outs, errs = proc.communicate()\n",
    "        out_errs = errs.decode(\"ascii\")\n",
    "        out_log = open(log_out, \"w\")\n",
    "        out_log.write(out_errs)\n",
    "        out_log.close()\n",
    "        execution = file_out\n",
    "    except Exception as e3:\n",
    "        print(str(e3))\n",
    "        execution = None\n",
    "    return execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "STEP 6: Picard to perform AddOrReplaceReadGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def call_picard_groups():\n",
    "def call_picard_groups(input_picard_md, picard_arrg_output = \"picard_arrg_output\", my_path = \"./\"):\n",
    "    execution = 0\n",
    "    try:\n",
    "        if not os.path.exists(picard_arrg_output):\n",
    "            os.makedirs(picard_arrg_output)\n",
    "        file_out = \"{}/{}/{}.arrg.mrkdup.sorted.bam\".format(my_path,picard_arrg_output,sample_name)\n",
    "        #print(file_out)\n",
    "        log_out =  \"{}/picard.arrg.mrkdup.sorted.bam.log\".format(my_path)\n",
    "        #print(log_out)\n",
    "            \n",
    "        #run gatk HaplotypeCaller\n",
    "        cmd = \"java -jar /usr/local/anaconda/share/picard-2.14-0/picard.jar AddOrReplaceReadGroups I={} O={} RGLB=lib1 RGPL=illumina RGPU=dummy RGSM={}\".format(input_picard_md, file_out, sample_name)\n",
    "\n",
    "        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        #get output and errors\n",
    "        outs,errs = proc.communicate()\n",
    "        \n",
    "        #write output (from byte to ascii)\n",
    "        out_errs = errs.decode(\"ascii\")\n",
    "        out_log = open(log_out, \"w\")\n",
    "        out_log.write(out_errs)\n",
    "        out_log.close()\n",
    "        execution = file_out\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        execution = 1\n",
    "    return execution  #return the proc object inclunding binary output and error log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "STEP 7: Samtools to index the Step6 .bam files output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def call_samtools_index():\n",
    "def call_samtools_index(input_picard_arrg, picard_arrg_output = \"picard_arrg_output\", my_path = \"./\"):\n",
    "    execution = 0\n",
    "    try:\n",
    "        if not os.path.exists(input_picard_arrg):\n",
    "            os.makedirs(input_picard_arrg)\n",
    "\n",
    "        file_out = \"{}\".format(input_picard_arrg) \n",
    "        #file_out = \"{}/{}/{}.arrg.mrkdup.sorted.bam\".format(my_path,picard_arrg_output,sample_name)\n",
    "        #print(file_out)\n",
    "        log_out =  \"{}/picard.arrg.mrkdup.sorted.bam.log\".format(my_path)\n",
    "        #print(log_out)\n",
    "        cmd = \"samtools index {}\".format(file_out)\n",
    "        proc = subprocess.Popen(cmd, shell = True, stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "        #print(cmd)\n",
    "        \n",
    "        # get errors\n",
    "        outs,errs = proc.communicate()\n",
    "        out_errs = errs.decode(\"ascii\")\n",
    "        out_log = open(log_out, \"w\")\n",
    "        out_log.write = (out_errs)\n",
    "        out_log.close()\n",
    "        execution = file_out\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        execution = 1\n",
    "    return execution  #return the proc object inclunding binary output and error log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "STEP 8: Genome Analysis ToolKit to perform SNP calling on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_gatk(refpath, bamfile, gatk_out = \"gatk_out\", my_path = \"./\", conf = 30):\n",
    "    execution = 0\n",
    "    try:\n",
    "        if not os.path.exists(gatk_out):\n",
    "            os.makedirs(gatk_out)\n",
    "        print(\"test\")\n",
    "        #run gatk HaplotypeCaller\n",
    "        out_file_name = os.path.basename(bamfile).split(\".ba\")[0]\n",
    "        print(out_file_name)\n",
    "        file_out = \"{}/{}/{}.vcf\".format(my_path,gatk_out,out_file_name)\n",
    "        print(file_out)\n",
    "        cmd = \"gatk -T HaplotypeCaller -R {} -I {} --genotyping_mode DISCOVERY -stand_call_conf {} -o {}\".format(refpath, bamfile, conf, file_out)\n",
    "        print(cmd)\n",
    "        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        #get output and errors\n",
    "        outs,errs = proc.communicate()\n",
    "        out_log =  open(\"{}.log\".format(file_out), \"w\")\n",
    "\n",
    "        #write output (from byte to ascii) in .sam\n",
    "        out_errs = errs.decode(\"ascii\")\n",
    "        out_log.write(out_errs)\n",
    "        out_log.close()\n",
    "        execution = file_out\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        execution = 1\n",
    "    return execution  #return the proc object inclunding binary output and error log\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "MAIN FUNCTION  to call sequencially steps 1-8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--ref REFGEN] [--R1 FASTQ_R1]\n",
      "                             [--R2 FASTQ_R2]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1009/jupyter/kernel-cd836778-050e-4a20-a7a3-a9e3eeca3887.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # arparse to pass arguments at launch \n",
    "    parser = argparse.ArgumentParser(description='run snp calling pipeline')\n",
    "    parser.add_argument('--ref', action=\"store\", dest= \"refgen\", help= 'path to reference genome.fa')\n",
    "    parser.add_argument('--R1', action=\"store\", dest= \"fastq_R1\", help = 'fastq file R1')\n",
    "    parser.add_argument('--R2', action=\"store\", dest= \"fastq_R2\", help = 'fastq file R2')\n",
    "    #parser.add_argument('-t', action=\"store\", dest= \"threads\", help = 'bwa threads number')\n",
    "    parser.parse_args()\n",
    "    \n",
    "    #### BWA function\n",
    "    #################\n",
    "    \n",
    "    # create bwa output folder\n",
    "    if not os.path.exists(bwa_output):\n",
    "            os.makedirs(bwa_output)\n",
    "    out_file_name = fastq_r1.split(\"_\")[0]\n",
    "    file_out = \"{}/{}/{}.sam\".format(my_path,bwa_output,out_file_name)\n",
    "    #print(file_out)\n",
    "    log_out =  \"{}/{}.log\".format(my_path,bwa_output)\n",
    "\n",
    "    # get function output and  error:\n",
    "    filepath_bwa = call_bwa(refgen, fastq_r1, fastq_r2, threads=threads)\n",
    "    if filepath_bwa is None:\n",
    "        print('\"something went wrong in bwa\"')\n",
    "        sys.exit(1)\n",
    "    #print('out_bwa',filepath_bwa)\n",
    "    #sys.exit(0)\n",
    "    \n",
    "    #### SAM function\n",
    "    #################\n",
    "    \n",
    "    input_sam = filepath_bwa\n",
    "    #print(input_sam)\n",
    "    sample_name = os.path.basename(input_sam)\n",
    "    sample_name = os.path.splitext(sample_name)[0]\n",
    "    #print(sample_name)\n",
    "    \n",
    "    # get function output and  error: \n",
    "    filepath_samtool = call_samtools_sort(input_sam)\n",
    "    if filepath_samtool is None:\n",
    "        print('\"something went wrong in samtools\"')\n",
    "        sys.exit(1)\n",
    "    print(filepath_samtool)\n",
    "    #sys.exit(0)\n",
    "    \n",
    "    #### PICARD FAIDX\n",
    "    #################\n",
    "    \n",
    "    # creating sequence dictionary with Picard\n",
    "    \n",
    "    input_ref = sys.argv[1] #full path to ref fasta\n",
    "    #outpath = sys.argv[2]\n",
    "    \n",
    "    picard = run_picard_CSD(input_ref)\n",
    "    samtools = run_samtools_faidx(input_ref)\n",
    "    #print('outvalue of picard', picard)\n",
    "    #print('outvalue of samtools', samtools)\n",
    "    run_picard_CSD(input_ref)\n",
    "    run_samtools_faidx(input_ref)\n",
    "    #sys.exit(0)\n",
    "    \n",
    "    #### PICARD MD function\n",
    "    ####################\n",
    "    # Function will return a '.mrkdup.sorted.bam' file\n",
    "    \n",
    "    input_bam = filepath_samtool\n",
    "    #print(input_bam)\n",
    "    sample_name = (os.path.basename(input_bam)).split('.')[0]\n",
    "    #print(sample_name)\n",
    "    #my_path = os.getcwd()\n",
    "    #print('current_dir', dir_path)\n",
    "    \n",
    "    # get function output and  error:\n",
    "    filepath_picard_md = call_picard_md(input_bam)\n",
    "    if filepath_picard_md is None:\n",
    "        print('\"something went wrong in Picard_MD\"')\n",
    "        sys.exit(1)\n",
    "    print('picard MD', filepath_picard_md)\n",
    "    #sys.exit(0)\n",
    "                \n",
    "    ##### PICARD function ARRG\n",
    "    ##########################\n",
    "    \n",
    "    input_picard_md = filepath_picard_md\n",
    "    #print(input_picard_md)\n",
    "    sample_name = (os.path.basename(input_picard_md)).split('.')[0]\n",
    "    #sample_name = os.path.basename(input_bam).split(\".\")\n",
    "    #print(sample_name)\n",
    "    \n",
    "    outpath = sys.argv[2]\n",
    "    \n",
    "    filepath_picard_arrg = call_picard_groups(input_picard_md)\n",
    "    print(filepath_picard_arrg)\n",
    "    \n",
    "    if filepath_picard_arrg is None:\n",
    "        print('\"something went wrong in Picard_ARRG\"')\n",
    "        sys.exit(1)\n",
    "    print('picard arrg',filepath_picard_arrg)\n",
    "    #sys.exit(0)                    \n",
    "\n",
    "    #### Samtool indexing\n",
    "    #####################\n",
    "    # take a aarg.mrkdup.sorted.bam file and index it.\n",
    "    # Function will return a 'aarg.mrkdup.sorted.bam.bai' file\n",
    "    # We will use the function as one step in our 'pipeline'.\n",
    "    \n",
    "    input_picard_arrg = filepath_picard_arrg\n",
    "    print('input_picard_arrg', input_picard_arrg)\n",
    "    #sample_name = (os.path.basename(input_bam)).split('.')[0]\n",
    "    sample_name = (os.path.basename(input_picard_arrg)).split('.')[0]\n",
    "    #print(sample_name)\n",
    "    \n",
    "    filepath_picard_arrg = call_samtools_index(input_picard_arrg)\n",
    "    print(filepath_picard_arrg)\n",
    "        \n",
    "    if filepath_picard_arrg is None:\n",
    "        print('\"something went wrong in Picard indexing\"')\n",
    "        sys.exit(1)\n",
    "    print('samtool indexing',filepath_picard_arrg)\n",
    "    #sys.exit(0)\n",
    "                                        \n",
    "    #### run GATK\n",
    "    #############\n",
    "    \n",
    "    \n",
    "    #get input  params\n",
    "    refpath = sys.argv[1]\n",
    "    print(refpath)\n",
    "    bamfile = filepath_picard_arrg\n",
    "    print(bamfile)\n",
    "    \n",
    "    #conf = int(sys.argv[3])\n",
    "    #outpath = sys.argv[4]\n",
    "    \n",
    "    #sample_name = (os.path.basename(bamfile)).split('.')[0]\n",
    "    #print(sample_name)\n",
    "    \n",
    "    \n",
    "    filepath_gatk = run_gatk(refpath, bamfile)\n",
    "    print(filepath_gatk)\n",
    "    \n",
    "    if filepath_gatk is None:\n",
    "        print('\"something went wrong in GATK\"')\n",
    "        sys.exit(1)\n",
    "    print(filepath_gatk)\n",
    "    #sys.exit(0)               \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## element to be taken care of:\n",
    "\n",
    "-Current script requires input files to be in the same dir (or sim-linked).\n",
    "-Remove current file creation from specific function and pass them through the Main function.\n",
    "-Redirect log files to specific folders and append sample name.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
